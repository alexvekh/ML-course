import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn.metrics import balanced_accuracy_score
from sklearn.impute import SimpleImputer
from imblearn.over_sampling import SMOTE
from prosphera.projector import Projector

# %%
# особливості побудови класифікатора на основі дерева рішень
# набір даних Національного інституту діабету, захворювань органів травлення та нирок.
# Задача класифікації — прогнозування наявності чи відсутності діабету в пацієнта. 
# Усі спостереження обмежуються даними про жінок віком від 21 року з індіанського племені Піма.

# Завантажимо дані та розглянемо їх, щоб зрозуміти, які ознаки доступні для використання в моделі.
data = pd.read_csv('../datasets/mod_03_topic_06_diabets_data.csv')
data.head()

# Отже, у наборі даних маємо такі ознаки:
 # Pregnancies: кількість попередніх вагітностей.
 # Glucose: концентрація глюкози в плазмі через 2 години після перорального тесту на толерантність до глюкози.
 # BloodPressure: діастолічний артеріальний тиск у мм рт. ст.
 # SkinThickness: Товщина складки шкіри трицепса в мм.
 # Insulin: Рівень інсуліну в сироватці крові через 2 години після прийому глюкози (в мОд/мл).
 # BMI (індекс маси тіла): Визначається як вага в кілограмах, поділена на квадрат висоти в метрах.
 # DiabetesPedigreeFunction: відображає схильність до діабету в сім'ї пацієнта.
 # Age: вік пацієнта в роках.
 # Outcome: цільова змінна.

# %%
# Перевірка типів даних і відсутніх значень

data.info()

# У наборі даних маємо всі числові ознаки, колонки з пропущеними значеннями відсутні. 
# Проте можна побачити, що для окремих ознак ('Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI') 
# значення дорівнюють 0, що може вказувати на некоректність даних.

# Це може бути пов’язано із різними причинами, включаючи технічні помилки або відсутність вимірювання. 
# Тому ми спочатку замінимо 0 в цих колонках на np.nan, а пізніше відновимо ці пропуски за допомогою SimpleImputer.

# %%

# Припускаємо, що рівень глюкози та індекс маси тіла можуть бути важливими ознаками наявності діабету.
# Спробуємо візуалізувати цю гіпотезу й побудувати графік, який показує, як рівень глюкози 
# та індекс маси тіла пов'язані з ознакою діабету (цільовою змінною) в нашому наборі даних.

X, y = (data.drop('Outcome', axis=1), data['Outcome'])

cols = ['Glucose',
        'BloodPressure',
        'SkinThickness',
        'Insulin',
        'BMI']

X[cols] = X[cols].replace(0, np.nan)

# %%

ax = sns.scatterplot(x=X['Glucose'], y=X['BMI'], hue=y)
ax.vlines(x=[120, 160],
          ymin=0,
          ymax=X['BMI'].max(),
          color='black',
          linewidth=0.75)

plt.show()

# На графіку видно, що для певної групи пацієнтів із рівнем глюкози вище заданого значення 
# (ми задали довільні значення для ознаки Glucose на рівнях 120 і 160 та позначили їх чорними лініями) 
# можна доволі ефективно спрогнозувати наявність діабету (множина помаранчевих точок справа).

# Проте існує "сіра" зона (між двома чорними лініями), де пацієнти з діабетом та здорові пацієнти перетинаються. 
# Наявність другої ознаки (індекс маси тіла) поки що не дуже допомогла нам візуально відокремити здорових пацієнтів у цій "сірій" зоні.

# Загалом, очевидно, що для побудови алгоритму та визначення правил діагностування діабету тільки цих двох ознак буде недостатньою.
# %%
#  Дерева рішень нечутливі до масштабу та розподілу вхідних даних. 
 # 1- визначають порядок застосування ознак для розбиття вибірки на основі відносних критеріїв (коефіцієнт Джіні або ентропія), на які не впливає масштаб.
 # 2. є непараметричними моделями, тобто не мають фіксованої кількості параметрів, які необхідно оцінити на основі вхідних даних. (На відміну від лінійної регресії, де ми оцінювали коефіцієнти для кожної із вхідних ознак у тренувальній вибірці, дерева рішень будуються шляхом рекурсивного розбиття даних.)
 # 3. не можуть невиправдано надати більшої ваги одній ознаці перед іншою через різницю в їхньому масштабі. У процесі побудови дерева кожна ознака розглядається незалежно, а рішення про розбиття вибірки на підмножини приймається на основі відносних критеріїв.
# Тому не треба масштабування чи нормалізації, а одразу розбиваємо на тренувальну і тестову вибірки

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.3,
    random_state=42)

# %%
# Перед навчанням необхідно відновити пропуски, які утворились внаслідок заміни на np.nan некоректних значень

imputer = SimpleImputer()

X_train[cols] = imputer.fit_transform(X_train[cols])
X_test[cols] = imputer.fit_transform(X_test[cols])

# %%
# Будуємо модель за допомогою об’єкта DecisionTreeClassifier бібліотеки sklearn 
# та одразу використовуємо навчену модель для прогнозування класів тестової вибірки. 
# Оцінимо точність класифікатора за допомогою метрики balanced accuracy.
# ("Вalanced accuracy" адаптований варіант accuracy у задачах бінарної та мультикласової класифікації з незбалансованими наборами даних.)

clf = (tree.DecisionTreeClassifier(
    random_state=42)
    .fit(X_train, y_train))

y_pred = clf.predict(X_test)

acc = balanced_accuracy_score(y_test, y_pred)

print(f'Acc.: {acc:.1%}')

# Точність (balanced accuracy) досягає ~70%. Добре це чи погано не скажеш без контексту. 
# Далі побудуємо “оптимізоване” дерево рішень, оцінимо його точність і порівняємо.

# %%
# візуалізуємо наше “базове” дерево рішень.

plt.figure(figsize=(80, 15), dpi=196)

tree.plot_tree(clf,
               feature_names=X.columns,
               filled=True,
               fontsize=6,
               class_names=list(map(str, y_train.unique())),
               rounded=True)

plt.savefig('../derived/mod_03_topic_06_decision_tree.png')
plt.show()

# Бачимо, що дерево складне й заплутане.("гіллясте" або "кущисте")
# Складне дерево не завжди "вдале". Якщо в дереві багато “сценаріїв” (ієрархічно структурованих наборів правил), 
# то кожен містить у собі меншу кількість спостережень.
# У таких "перенавчених" дерев здатність до узагальнення зменшується, і моделі будуть давати менш точні прогнози на тестовій вибірці.
# Для уникнення надмірно великих розмірів дерев можна використовувати додаткові параметри під час створення об'єкта DecisionTreeClassifier.
# Ці параметри вказують алгоритму використовувати спеціальні процедури (критерії зупинки), які сприяють створенню оптимального дерева "вдалого розміру". 
#  Зробимо це трохи згодом, після аналізу розподілу цільової змінної.

# %%

# Балансування класів
# Перед тим, як “оптимізувати” наше дерево, подивимось на розподіл класів цільової змінної.

y_train.value_counts(normalize=True)

# спостерігаємо певний дисбаланс класів. 
# У задачах класифікації це може призвести до того, що модель, навчена на незбалансованих даних, 
# почне виявляти певну упередженість та неправильно визначати менш представлений клас.

# Щоб вирішити це, можемо використати підхід oversampling (штучне насиченя даних додатковими спостереженнями менш представленого класу).
# У датасет можна додати об’єкти, копіюючи (дублюючи) спостереження із менш представленого класу, або використати більш складні алгоритми для генерації таких спостережень.
# Такий підхід гарантує, що модель отримає більш справедливе уявлення про обидва класи під час навчання та уникне упередженості. 
# Він допомагає моделі правильно визначати “межу прийняття рішення” (decision boundary) при розділі простору ознак на підмножини для кожного класу.

# На відміну від використання параметра class_weight (ваги класів), як ми це робили в логістичній регресії, коли алгоритм надавав різні ваги класам під час навчання, 
# підхід oversampling безпосередньо збільшує кількість спостережень менш представленого класу в тренувальній вибірці. Це дозволяє краще навчатися за рахунок додаткових об’єктів.

# %%
# Для генерації додаткових спостережень ми можемо використати бібліотеку imblearn. Застосуємо екземпляр об’єкта SMOTE цієї бібліотеки 
# до нашого тренувального набору та оцінимо розподіл класів після додавання до нього квазі-нових негативних спостережень.

sm = SMOTE(random_state=42, k_neighbors=15)
X_res, y_res = sm.fit_resample(X_train, y_train)

y_res.value_counts(normalize=True)

# Тепер маємо рівномірний розподіл спостережень за класами.

# %%
# Додаткові параметри навчання
# Сробуємо створити нове дерево на збалансованому наборі даних. Цього разу ми встановимо обмеження на максимальну глибину дерева (параметр max_depth), щоб зберегти його структуру простою.
# Такі параметри називають “гіперпараметрами”. Правильно підібрані та налаштовані гіперпараметри можуть значно вплинути на процес навчання та ефективність моделі. 
# Знайомство з гіперпараметрами алгоритму слід починати з вивчення офіційної документації відповідного об’єкта бібліотеки (наприклад, DecisionTreeClassifier).

# Будуємо нове дерево й оцінюємо його точність.

clf_upd = (tree.DecisionTreeClassifier(
    max_depth=5,
    random_state=42)
    .fit(X_res, y_res))

y_pred_upd = clf_upd.predict(X_test)

acc = balanced_accuracy_score(y_test, y_pred_upd)

print(f'Acc.: {acc:.1%}')

# %%
# Завдяки збалансуванню вхідних даних та оптимізації гіперпараметрів дерева рішень нам вдалося підвищити точність прогнозів на тестовій вибірці (з 70,2% до 73,4%). 
# До того ж, ми отримали значно простішу структуру дерева, яка полегшує розуміння та використання моделі.

plt.figure(figsize=(30, 8))

tree.plot_tree(clf_upd,
               feature_names=X.columns,
               filled=True,
               fontsize=8,
               class_names=list(map(str, y_res.unique())),
               rounded=True)

plt.show()

# %%
# Важливість ознак у моделі
# Дерево рішень допомагає виявляти складні зв'язки в даних і дає користувачам можливість легко інтерпретувати та оцінювати важливість вхідних ознак через їхній вплив на прогнозовані результати.
# Основна ідея визначення важливості ознак в оцінці, наскільки ефективно кожна окрема ознака сукупно впливає на прийняття рішення. 
# Цю ефективність можна обчислити як загальний внесок, який ознака робить у зниження критерію розбиття (наприклад, коефіцієнта Джині) на всіх рівнях дерева (по всіх внутрішніх вузлах, для яких вона використовується). 
# Ознаки з найбільшим таким внеском (часткою) вважаються більш важливими.

# Інформацію про важливість ознак можна використовувати для подальшої оптимізації моделі та поліпшення зрозумілості її прогнозів. 
# Нормалізовані значення "важливості" ознак знаходяться в атрибуті .feature_importances_ навченого екземпляра об’єкта DecisionTreeClassifier.

(pd.Series(
    data=clf_upd.feature_importances_,
    index=X.columns)
    .sort_values(ascending=True)
    .plot
    .barh())

plt.show()

# Отже, ми можемо підтвердити, що ознаки Glucose і BMI дійсно виявилися серед найважливіших при діагностиці діабету, як ми й передбачали на початку аналізу. 
# Проте, як видно з отриманих результатів, ще одним важливим чинником для прогнозування захворювання в пацієнта також є його вік.

# %%

visualizer = Projector()
visualizer.project(data=X_train, labels=y_train)

