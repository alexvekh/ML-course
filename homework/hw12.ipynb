{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кластеризація методом k-means.\n",
    "\n",
    "# pip install yellowbrick\n",
    "# conda install kneed\n",
    "\n",
    "import warnings\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from kneed import KneeLocator\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Завантажте набір даних Concrete.\n",
    "with open('../datasets/mod_05_topic_10_various_data.pkl', 'rb') as fl:\n",
    "    datasets = pickle.load(fl)\n",
    "\n",
    "concrete = datasets['concrete']\n",
    "concrete.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Використайте прийом підрахунку кількості для створення нової ознаки Components, \n",
    "    # яка вказуватиме на кількість задіяних складових у різних рецептурах бетону.\n",
    "components = ['Cement',\n",
    "              'BlastFurnaceSlag',\n",
    "              'FlyAsh',\n",
    "              'Water',\n",
    "              'Superplasticizer',\n",
    "              'CoarseAggregate',\n",
    "              'FineAggregate']\n",
    "\n",
    "concrete['Components'] = concrete[components].gt(0).sum(axis=1)    # .greater than 0 .sum(axis=1): підсумовує результат по рядках.\n",
    "\n",
    "concrete[components + ['Components']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Нормалізуйте набір даних за допомогою об’єкта StandardScaler з пакета sklearn для подальшої кластеризації.\n",
    "X = StandardScaler().fit_transform(concrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Визначте оптимальну кількість кластерів за допомогою об'єкта KElbowVisualizer з пакета yellowbrick.\n",
    "# 4a). розрахунок головних компонент\n",
    "pca = PCA(random_state=42).fit(X)\n",
    "pve = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4b). Пошук оптимальноъ кількості головних компонетн за \"правилом ліктя” на графіку дисперсії (змінності) даних\n",
    "sns.set_theme()\n",
    "\n",
    "kneedle = KneeLocator(\n",
    "    x=range(1, len(pve) + 1),\n",
    "    y=pve,\n",
    "    curve='convex',\n",
    "    direction='decreasing')\n",
    "\n",
    "kneedle.plot_knee()\n",
    "\n",
    "plt.show()\n",
    "# Визначена візуально за “правилом ліктя” оптимальна кількість головних компонент дорівнює 6.\n",
    "# Проте цікаво спробувати й 4, оскільки це ближче емпіричного до правила 1:10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4c). Визначимо й візуалізуємо на графіку кумулятивну частку змінності даних, яку пояснюють 9 перших головних компонент:\n",
    "n_components = kneedle.elbow\n",
    "\n",
    "ax = sns.lineplot(np.cumsum(pve))\n",
    "\n",
    "ax.axvline(x=n_components,\n",
    "           c='black',\n",
    "           linestyle='--',\n",
    "           linewidth=0.75)\n",
    "\n",
    "ax.axhline(y=np.cumsum(pve)[n_components],\n",
    "           c='black',\n",
    "           linestyle='--',\n",
    "           linewidth=0.75)\n",
    "\n",
    "ax.set(xlabel='number of components',\n",
    "       ylabel='cumulative explained variance')\n",
    "\n",
    "plt.show()\n",
    "# Отже, після зменшення розмірності даних ми зберігаємо приблизно 97% “інформативності” вхідного. (дуже високий показник)\n",
    "# У випадку 4 - 92%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4d). Зменшуємо розмірність даних за допомогою PCA:\n",
    "X = pca.transform(X)[:, :n_components]\n",
    "#  X = pca.transform(X)[:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4e). Кластеризація набору даних. Визначення кількості кластерів за допомогою KMeans\n",
    "model_kmn = KMeans(random_state=42)\n",
    "\n",
    "visualizer = KElbowVisualizer(\n",
    "    model_kmn,\n",
    "    k=(2, 10),\n",
    "    timings=False)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "    visualizer.fit(X)\n",
    "\n",
    "visualizer.show()\n",
    "# Визначена оптимальна кількість кластерів для цього набору даних за “правилом ліктя” дорівнює 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Проведіть кластеризацію методом k-середніх і отримайте мітки для кількості кластерів, визначеної на попередньому кроці.\n",
    "k_best = visualizer.elbow_value_\n",
    "# k_best = 3\n",
    "model_kmn = KMeans(n_clusters=k_best, random_state=42).fit(X)\n",
    "\n",
    "labels_kmn = pd.Series(model_kmn.labels_, name='k-means')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Візуалізація 2D\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels_kmn, cmap='viridis', s=50)\n",
    "plt.title(f'Visualization of {k_best} clusters')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar(label='Cluster label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Візуалізація 3D\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X)\n",
    "# X_pca = X # Візуалізація по першим головним компонентам\n",
    "\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], \n",
    "                     c=labels_kmn, cmap='viridis', s=50)\n",
    "# Заголовки та підписи осей\n",
    "ax.set_title(f'3D Visualization of {k_best} Clusters')\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "# Кольорова шкала\n",
    "cbar = fig.colorbar(scatter, ax=ax, pad=0.1)\n",
    "cbar.set_label('Cluster label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Використайте оригінальний набір вхідних даних для розрахунку описової статистики кластерів («звіту»): \n",
    "    # розрахуйте медіани для кожної ознаки, включаючи підрахунок кількості компонент по кожному кластеру за допомогою методу groupby.\n",
    "data = concrete.copy()\n",
    "data['Cluster'] = labels_kmn\n",
    "\n",
    "cluster_medians = data.groupby('Cluster').median()\n",
    "print(\"Cluster medians:\")\n",
    "print(cluster_medians)\n",
    "\n",
    "cluster_counts = data.groupby('Cluster').size().rename('Count')\n",
    "print(\"Cluster counts:\")\n",
    "print(cluster_counts)\n",
    "\n",
    "report = pd.concat([cluster_medians, cluster_counts], axis=1)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Додайте до звіту кількість об'єктів (рецептур) у кожному з кластерів.\n",
    "report.columns = [f'Median {col}' for col in report.columns[:-1]] + ['Count']\n",
    "report.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_reset = report.reset_index()\n",
    "melted = report_reset.melt(id_vars=['Cluster'])\n",
    "\n",
    "g = sns.FacetGrid(melted, \n",
    "                  col='variable', \n",
    "                  col_wrap=3, \n",
    "                  sharex=False, \n",
    "                  sharey=False)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    g.map(sns.barplot, 'Cluster', 'value')\n",
    "# Заголовки та підписи осей\n",
    "g.set_titles(col_template='{col_name}')\n",
    "g.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Проаналізуйте звіт та зробіть висновки.\n",
    "\n",
    "№Висновки:\n",
    "# Спроба без зменшення розмірності датасету а також спроба зменшення розмірності до 4 головних компонент замість 6 (що теж візуально виглядало допустимим за \"правилом ліктя\") помітних змін не привнесло. \n",
    "# В будь якому випадку k-means визначав найбільш опримальним 5 кластерів\n",
    "\n",
    "# Візуально здається, що кластеризація відбулася на сама вдала, чітких кордонів між кластерами не спостерігається. Кластери перемішуються і зачіпають простір інших, шо може говорити про занадто високу кількість кластерів.\n",
    "\n",
    "# На діарамах добре видно що приміс шлаку відсутній у цементі кластерів 0 та 4, А зола відсутня у кластрах 1, 3 та 4. \n",
    "# Крым того Суперпластифікатор відсутній у кластарі 4 \n",
    "# І оскільки решта ознак більш менг рівномірні, схоже, це основна логіка розділення на кластари.\n",
    "# Так якщо цемент не мамє шлаку, але має золу = 0 кластер\n",
    "#      не має золи, клаку та суперпластифікатора = 4\n",
    "#      має шлак і золу  = 2\n",
    "#      а 1 та 3, які мають шлак та не мають золи, треба шукати у інших ознаках:\n",
    "#          таких як кількість цементу, в 1 біля 200, а в 3 - біля 400 \n",
    "#          та Міцність на стиск, в 1 до 40, а в 3 - під 60\n",
    "#          тобто решта рецептур ділиться на 2 кластери по міцності (більше цементу дає більше міцності, менше цементу - менше міцності )\n",
    "# Тому і бачимо, що найменге компонентів у кластері 4 (4 компонета), найбільше у кластері 2 (7 компонентів). Цікаво що середня кількість компонентів з 60 - 120 спостережень виявиляся цілим числом, що говорить про чітке попадання рецептур з 4 або 7 компонентами до своїх кластерів, що підтверджує залежність кластеризаціє саме від компонентів.   \n",
    "\n",
    "# Варто сказати також про можливість кластеризації на 3 кластери (виявлено хляхом спроб). Достатьо чіткі кордони, та на 3D візуалізаціє видно що компонети шикуються в рядочки, немов би рецептури формувались штучно (наприклад, додаємо компоненту 120 грам, в наступний 130, 140, 150 і так далі, наким чином отримуємо серію рецептів)\n",
    "# 3 кластери чіткорозподіляються на 0 містить, але не золу, 1: Ні шлаку ні золи (і суперкласівкатора тут нема); 2: І шлак і золу (до речі, вполовині менше сементу тоді треба) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
